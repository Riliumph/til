# G検定メモ

## 1. AIとは

### 人工知能の分類

1. シンプルな制御プログラム  
   すべての振る舞いが予め決定されている。
   > e.g. 洗濯機の水量調整、エアコンの温度調整
2. 古典的な人工知能  
   探索・推論、知識データを利用して状況に応じた振る舞いをする
   > e.g. 掃除ロボット、診断プログラム
3. 機械学習を取り入れた人工知能  
   膨大なサンプルデータを下に入力と出力の関係を学習する
   > e.g. 検索エンジン、交通渋滞予測
4. Deep Learningを取り入れた人工知能  
   得寮寮変数を自動的に学習する
   - 特徴量：特徴が学習結果に大きく影響するかを判定している

### コンピュータの歴史

- 第一次AIブーム（推論・探索の時代）  
  - 1946年：汎用コンピュータENIACの完成
  - 1956年：ダートマス会議で「人工知能」の登場
    - マーヴィン・ミンスキー
    - ジョン・マッカーシー  
      > 人工知能という言葉を使い始めた
    - アレン・ニューウェル
    - ハーバード・サイモン
  - 1960年：解決できるの**トイ・プロブレム**だけかよ、がっかりだぜ
- 第二次AIブーム（知識の時代）  
  - 1980年：DBを使った**エキスパート・システム**の完成
    > 日本では**第５世代コンピュータ**とかダッセェ名前がつけられる
  - 1995年：知識膨大すぎて人間には管理できねーじゃん、バカヤロー
  - 第三次AIブーム（機械学習・特徴表現学習の時代）
    **ビッグデータ**とかいうバズワードを使って機械学習　　
    特徴量という知識要素を機械に学習させるDeep Learningが話題に  
    > レイ・カーツワイル「**シンギュラリティー**が危ない」

## 2-1. 探索・推論

迷路問題は**探索木**に置き換えているだけ。

**場合分け**を解くには探索法を用いる。

- 幅優先探索
- 深さ優先探索

### 幅優先探索

階層を最優先要素として、その階層を探索したら次の階層を探索する方法。  
階層は下方向なので深さ優先と思いがちだが、その階層を全部探索しないと次に行けないので横方向が最優先要素であると理解すればいい。

階層を全チェックすることから、常に最短ゴールすることができる。  
ただし、ルートを全記憶する必要があるのでメモリ不足に悩まされる。

### 深さ優先探索

とりあえず、末節まで行くまで行ってそれが答えか判断する方法。

答えじゃなかったらそのルートをメモリから削除できるのでメモリ不足は発生しにくい。  
ただ、それが答えかどうかは運ゲーなので時間がかかる。

### ロボットの行動計画

ロボットも結局は探索。  
**プランニング**と呼ぶ。

- STRIPS(Stanford Research Institute Problem Solver)  
  前提条件・行動・結果の組み合わせを
- SHRDLU（しゅるどぅるー）  
  テリー・ウィノグラードのプログラミング言語。システムか。  
  **Cyc**プロジェクトに派生する
  テリー・ウィノグラードはGoogleのラリー・ペイジを育てている。

### ボードゲーム

Google傘下に下ったディープマインド社の**AlphaGo**  
もはや、探索法では無理ゲー

|ゲーム|目地数|組み合わせ数|
|:--:|:--:|:--|
|オセロ|8x8|白黒裏返しあり→約10^60|
|チェス|8x8|白黒6種→約10^120|
|将棋|9x9|8種。ただし、獲得駒が使える→約10^220|
|囲碁|19x19|白黒→約10^360|

#### Min-Max法

自分が指すときにスコアが最大になるようにする。

- アルファカット  
  最小スコアを選ぶ過程で、すでに出現したスコアより大きいノードが出たらそれ以降をスキップする
- ベータカット  
  最大スコアを選ぶ過程で、スコアが小さいノードが出たらそれ以降をスキップする

#### モンテカルロ法

ゲームは探索数が膨大なだけでなく、その**コスト評価**に原因があるという考え。  
ある程度ゲームが進むと、スコア評価を放棄する。

コンピューターは秒間ですごい数のシミュレーションができるので、２プレイヤー用意して無限に手を打たせ続ける訳ですよ。序盤は盤面が広すぎてシミュレーションパターン多すぎて無理ですけど、後半盤面が小さくなってくるとパターン洗い出した方が良い成果が出るって寸法。
簡単に言うとブルートフォースシミュレーションみたいな。

## 2-2. 知識表現

### 人工無能

チャットボットとか。

- ELIZA（イライザ）  
  1964年頃からジョゼフ。ワイゼンバウムによって作成された。  
  相手の発言を予め用意されたパターンと比較して合致したパターンを返す。  
  相手が会話していると勘違いすることを**イライザ効果**と言う。
  > うーん、シーマンみたいな？  
  > アレはシーマン側から質問するからAIじゃないけど
  
### エキスパートシステム

- MYCIN（マイシン）  
  バクテリアの診断支援用エキスパートシステム
- DENDRAL  
  1960年に未知の有機化合物を特定するエキスパートシステム

#### エキスパートシステムの限界

エキスパートシステムは知識ベースが必要だが、人間の知識は経験則が多く暗黙的である。  
インタビューシステムも作られたが、一貫していない矛盾した知識もあり、知識ベースの保守が無理ゲーだった。

### 意味ネットワーク(semantic network)

認知心理学における長期記憶の構造モデルとして考案された。
is-a関係とかpart-of関係とかで色々書く。

### Cycプロジェクト

エキスパートシステムは知識ベースをうまく作用させるには、広範囲に及ぶ常識が必要になる。  
つまり、**一般常識をコンピュータに取り込もうプロジェクト**
ダグラス・レナートが1984年からスターと

#### オントロジー

知識の記述・整理が無理ゲーだったので**知識を体系化する手法**。
知識の共有と活用を目的とする。

- 重量オントロジー（ヘビーウェイトオントロジー）  
  意味論を人間が考えて手入力する方法。  
  Cycプロジェクトがソレ。
- 軽量オントロジー（ライトウェイトオントロジー）  
  自動解析する**ウェブマイニング**とか**データマイニング**とか  
  本当に正確じゃなくても使えるレベルに正確だったら良いよね論。
  BIMのワトソンとか。

#### ワトソン

IBMのAI。  
次の順番で処理。

1. 質問を分析
2. 複数の回答を候補
3. 質問との整合性・条件チェック
4. 総合点数の最高点を回答として採用

**質問の意味を理解するのではなく、質問に関連するキーワードを高速検索している。**

## 2-3. 機械学習

ビッグデータを使ってる

- レコメンデーションエンジン
- スパムフィルター

### ニューラルネットワーク

1958年：単純パーセプトロン

### ディープラーニング

ニューラルネットワークを多層にしたもの。

ILSVRCは画像認識コンペティション

## 人工知能分野の問題

### フレーム問題

1969年、ジョン・マッカーシー  
「今しようとしておることに関係がある事柄だけを選び出すことが、実は非常に難しい」

1. そのまま持ち出して爆発
2. 持ち出す方法の計算中に爆発
3. 持ち出す方法の計算方法を計算中に爆発

### チューリングテスト

アラン・チューリング
「別の場所にいる人間がコンピュータと会話し、相手がコンピュータだと見抜けなければコンピュータには知能があるとする」

### 強いAIと弱いAI

- 強いAI  
  適切にプログラムされたコンピュータは人間が心を持つのと同じ意味で心を持つ
- 弱いAI  
  コンピュータは人間の心を持つ必要はなく、有用な道具であればいい

ジョン・サール：中国語の部屋

### シンボルグラウンディング問題

スティーブン・ハルナッド  
「シンボルとその対象が以下にして結びつくか」

シマウマは縞と馬だが、コンピュータにその意味はわからない

### 知識獲得のボトルネック

- 1970年：ルールベース機械翻訳
- 1990年：統計的機械翻訳

## 代表的な手法

- 教師あり学習
- 教師なし学習
- 強化学習

### 教師あり学習

- 線形回帰  
  - ラッソ回帰（L1正則化）
  - リッジ回帰（L2正則化）
- ロジスティック回帰

#### ロジスティック回帰

- ２値分類：シグモイド関数
- 多値分類：ソフトマックス関数

0.5を境にして正負を決めるなどすることができる。  
しかし、スパムフィルターの感度を上げるために閾値0.5を上げて0.7にするとかいうケースも有る。

#### ランダムフォレスト

教師あり学習は、入力の特徴量をパターン出力するに尽きる。  
そこで、特徴量の値を順々に木構造にしていけば、最終的には答えに辿り着くだろうというモノ。  
木構造はランダムに作り、それらを並行して複数実行することで、最終的には多数決で答えを出す。多数決を行うことで集合知になり、モデルの精度が極端に悪い奴がいても均されていい感じの結果になる、

**ブートストラップサンプリング**を用いる。  
> データ全てを使わずに一部分だけランダムに使用するサンプリング方法

- アンサンブル学習  
  複数のモデルで学習すること
  - バギング  
    全体の一部のデータを複数のモデルで学習する方法  
    並行実行するのがミソ
  - ブースティング  
    一部のデータを繰り返し抽出し、複数のモデルで学習する  
    逐次実行するのがミソ
    - AdaBoost
    - 勾配ブースティング
    - XgBoost

#### Support Vector Machine

**マージン最大化**を行う手法。  

> マージン最大化  
> 入力データの各点との距離が最大になる境界線を求めるパターン分類

- 扱うデータが高次元の場合  
  超平面を考える
- 線形分離できない  
  **カーネル関数**を使ってデータを高次元写像する。  
  計算式が複雑になるのを防ぐために**カーネルトリック**を用いる。

#### ニューラルネットワーク

飛ばしまーす

#### k-means

教師なし学習の中で、データの構造や特徴を掴むための手法の一つ。  
クラスタを作るやつ。
重心が動かなくなるまで乱数でデータを動かし続ける。

#### 主成分分析(Principal Component Analysis)

これも飛ばす

## 手法の評価

- 交差検証  
  全データを学習用（訓練データ）と評価用（テストデータ）に分割して評価する
  - ホールドアウト検証  
    事前に訓練データとテストデータに分割する方法。  
    データが少ない場合、データに偏りが生じてたまたま評価が良くなるパターンが発生する。
  - k-分割交差検証  
    訓練データとテストデータの分割したあと、それらをローテーションして訓練データとテストデータのパターンを作る。そして、それらで学習と評価を行う。

データが分割されるパターン

- 全データ
  - 訓練データ
    - 訓練データ
    - 検証データ
  - テストデータ

## 評価指標

ベイズの定理で有名な問題を以下の**混同行列(Conduct Matrix)**で考える。

罹患率0.01%の病気について

|実際の値\予測値|陽性(Positive)|陰性(Negative)|
|:--:|:--:|:--:|
|罹患(Positive)|真陽性(True Positive)|偽陰性(False Negative)|
|非罹患(Negative)|偽陽性(False Positive)|真陰性(True Negative)|

- 正解率(Accuracy)  
  TP + TN / TP + TN + FP + FN  
  全体から正しく予測できた（当たった）確率。
- 適合率(Precision)  
  TP / TP + FP  
  陽性の中から、実際に罹患だった確率。
- 再現率(Recall)  
  TP / TP + FN  
  罹患の中から、実際に陽性だと判断できた確率
- F値(F measure)  
  (2 * precision * recall) / (precision + recall)  
  適合率と再現率の調和平均

### 正則化

- L1正則化（ラッソ回帰）  
  一部のパラメーラを０にすることで、特徴選択を行うことができる。
- L2正則化（リッジ回帰）  
  パラメータの大きさに応じて０に近づけることで、汎化された滑らかなモデルを得る。
- Elastic Net = L1 + L2


## ワード

- AI効果  
「単純な自動化であって知能とは関係ない」と結論づける人間心理  

- ロジック・セオリスト  
  世界初の人工知能プログラム

- 人工知能ってなんだ？  
  - 専門家にもわからない
  - 同じシステムでも専門家によって意見が違う
