# AI よもやま話

[マイクロソフトが自社でAIチップを開発せざるを得ない深刻理由、NVIDIA依存だけではない](https://www.sbbit.jp/article/st/113572)

---

## MSのチップ開発の背景

NVIDIAが2020年にリリースした「A100」というモデルが主に利用されているが価格は1～3万ドルほど。  
また、2022年にリリースされた後継モデル「H100」は、現在eBayで4万ドル以上で取り引きされているとのこと。

## Googleも作ってる

グーグルも最近自社で開発しているAIチップ「TPUv4」が「A100」のパフォーマンスを上回ったとする論文を公開するなど、NVIDIAに対する依存度を下げようという動きがテック大手企業で顕著となっている。  

> [グーグル・アマゾン vs エヌビディア、開発加速するAIチップ市場の行く末](https://www.sbbit.jp/article/cont1/113389)

## Latitudeのコスト半減策

AI開発のコストにまつわる現状はどうなっているのか、事例をみてみたい。  
[Latitude](https://latitude.io/)というスタートアップは、生成AIを活用したロールプレイングゲーム「AI Dungeon」を提供しているが、その生成技術はOpenAIのGPTモデルによって実現されていた。  
このゲームを運営するにあたってLatitudeは、OpenAIとAWSに利用料を支払っていたが、そのコストは毎月20万ドル（約2,700万円）に達していた。
これを受け同社は、コスト削減のためOpenAIからイスラエル拠点のAI21 Labsに乗り換え、またオープンソースや無料の言語モデルも取り入れることで、生成AI関連コストを半額以下に抑えることができたという。  

> [ChatGPT and generative AI are booming, but the costs can be extraordinary](https://www.cnbc.com/2023/03/13/chatgpt-and-generative-ai-are-booming-but-at-a-very-expensive-price.html)

## Metaの使用例

メタが最近リリースしたLLaMAモデルは、2048個の「A100」を使用し、1兆4000万のトークン（1000トークン＝約750ワード）をトレーニングしたが、その日数は21日に及んだ。  
これをAWSの利用価格に換算すると、240万ドルを超えるという。このLLaMAモデルのパラメータ数は650億で、ChatGPTのベースモデルが持つ1750億パラメータよりも小さいものである。

> [LLaMA: Open and Efficient Foundation Language Models](https://research.facebook.com/publications/llama-open-and-efficient-foundation-language-models/)

## Hugging Face

AIスタートアップのHugging FaceのCEO、クレマン・デラング氏は、同社のBloom大規模言語モデルのトレーニングには2カ月半以上かかり、500個のGPUに相当するスーパーコンピューターが必要であったと述べている。
